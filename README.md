# SmartCity-Realtime-Streaming-Data-Ingestion

This is an End to End Realtime data streaming pipeline covering each phase from data ingestion to processing and finally storage. the data is simulated using a python program which is further undergoes processing utilizing tools like Apache Zookeeper, Apache Kafka, Apache Spark, Docker, Python, AWS Cloud, AWS Glue, AWS Athena, AWS IAM, AWS Redshift and finally PowerBI to visualize data on Redshift.


# Architecture Diagram

![image](https://github.com/user-attachments/assets/e77b1b0e-40dd-4995-a3c3-821fbe8d0b25)

# Project Description

The project simulates the data for car travel between two cities in the United States, capturing data generated by the car, GPS data, camera data, weather data, and data related to any emergency situations the driver may encounter during the journey. Data is captured in real-time using Apache Kafka, which optimizes the system by efficiently handling high-throughput data streams. Apache Spark consumes this streaming data, providing significant speed in data processing due to its in-memory computation capabilities. The data processed by Apache Spark is stored in an Amazon S3 data lake, where it is transformed using AWS Glue Catalog. The transformed data is then stored in a target database in AWS Redshift with the help of DBeaver and can be used for further analysis. The cleaned data from Redshift can be fetched into Tableau, Power BI, or Looker Studio to gain actionable insights. Using Kafka and Spark ensures the system is optimized for real-time data capture and processing, significantly increasing the speed and efficiency of data handling and analysis.
